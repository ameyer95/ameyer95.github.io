---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

------
I research **multiplicity** in machine learning -- the fact that many models may perform equally well on a task according to standard accuracy metrics. Multiplicity can pose a problem for machine learning because individual decisions, if subject to change given multiplicity, become arbitrary. This arbitrariness may be unavoidable, but is often hidden, because alternative models and decisions are not considered.

My work specifically focuses on how **datasets** impact multiplicity: how different datasets may be equally well suited to a prediction task, yet yield models that behave differently in practice. My work uses techniques from *formal methods* and *machine learning* to computationally measure the impact that dataset multiplicity has on machine learning robustness. I am also branching out to using techniques from human-computer interaction to study gain a deeper understanding of how multiplicity in machine learning impacts fairness. 

I am currently a final-year PhD candidate in the Computer Sciences PhD program at the University of Wisconsin - Madison. I'm part of the [MadPL](https://madpl.cs.wisc.edu/) group and am co-advised by [Aws Albarghouthi](http://pages.cs.wisc.edu/~aws/) and [Loris D'Antoni](https://pages.cs.wisc.edu/~loris/).

## News
* January 2025 - My paper "Perceptions of the Fairness Impacts of Multiplicity in Machine Learning" was accepted to CHI! Very excited to travel to Japan this spring. 
* October 2024 - Attended the INFORMS conference in Seattle to present my work on dataset multiplicity. 
* April 2024 - Passed my preliminary exam and became a PhD candidate!
* March 2024 - This May, I will attend the [DMLR workshop](https://dmlr.ai/) at ICLR to present our paper, Verified Training for Counterfactual Explanation Robustness under Data Shift.

-----
## Publications
(+) Equal contribution

**Perceptions of the Fairness Impacts of Multiplicity in Machine Learning** <br/>
Anna P. Meyer, Yea-Seul Kim,  Aws Albarghouthi, and Loris D'Antoni <br/>
*CHI 2025* <br/>
[<a href="https://arxiv.org/abs/2409.12332">pdf</a>]

**On Minimizing the Impact of Dataset Shifts on Actionable Explanations** <br/>
Anna P. Meyer (+), Dan Ley (+), Suraj Srinivas, and Himabindu Lakkaraju <br/>
*UAI 2023* <span style="color:red">(*Oral Presentation*)</span><br/>
[<a href="http://arxiv.org/abs/2306.06716">pdf</a>] [<a href="https://github.com/AI4LIFE-GROUP/robust-grads">code</a>]<br/>
**The Dataset Multiplicity Problem: How Unreliable Data Impacts Predictions** <br/>
Anna P. Meyer, Aws Albarghouthi, and Loris D'Antoni <br/>
*FAccT 2023*<br/>
[<a href="https://arxiv.org/abs/2304.10655">pdf</a>] [<a href="https://youtu.be/KxsdeJrvym0">video</a>] [<a href="https://github.com/annapmeyer/linear-bias-certification">code</a>] <br/> 
**Certifying Robustness to Programmable Data Bias in Decision Trees**  <br/>
Anna P. Meyer, Aws Albarghouthi, and Loris D'Antoni <br/>
*NeurIPS 2021*<br/>
[<a href="https://arxiv.org/abs/2110.04363">pdf</a>] [<a href="/files/dec_trees_slides.pdf">slides</a>] [<a href="https://youtu.be/kf5Geyr71T4">video</a>] [<a href="https://github.com/annapmeyer/antidote-P">code</a>] <br/>


-----
## Preprints and workshop papers

**Verified Training for Counterfactual Explanation Robustness under Data Shift** <br/>
Anna P. Meyer (+), Yuhao Zhang (+), Aws Albarghouthi, and Loris D'Antoni <br/>
*DMLR workshop at ICLR 2024*<br/>
[<a href="https://arxiv.org/abs/2403.03773">pdf</a>] [<a href="https://github.com/ForeverZyh/robust_cfx">code</a>] <br/>

