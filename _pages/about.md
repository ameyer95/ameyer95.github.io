---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

------
I research **multiplicity** in machine learning -- the fact that many models may perform equally well on a task according to standard accuracy metrics. Multiplicity can pose a problem for machine learning because individual decisions, if subject to change given multiplicity, become arbitrary. This arbitrariness may be unavoidable, but is often hidden, because alternative models and decisions are not considered.

My work specifically focuses on how **datasets** impact multiplicity: how different datasets may be equally well suited to a prediction task, yet yield models that behave differently in practice. My work uses techniques from *formal methods* and *machine learning* to computationally measure the impact that dataset multiplicity has on machine learning robustness. I am also branching out to using techniques from human-computer interaction to study gain a deeper understanding of how multiplicity in machine learning impacts fairness. 

I'm currently in my fourth year in the Computer Sciences PhD program at the University of Wisconsin - Madison. I'm part of the [MadPL](https://madpl.cs.wisc.edu/) group and am co-advised by [Aws Albarghouthi](http://pages.cs.wisc.edu/~aws/) and [Loris D'Antoni](https://pages.cs.wisc.edu/~loris/).

## News
* March 2024 - This May, I will attend the [DMLR workshop](https://dmlr.ai/) at ICLR to present our paper, Verified Training for Counterfactual Explanation Robustness under Data Shift.
* Fall 2023 - As part of the [STEM Public Service Fellows](https://wiscience.wisc.edu/service/public-service-fellows/) program, I am working with UW-Madison's [Data Science Hub](https://datascience.wisc.edu/hub/) to develop a workshop on fair and explainable machine learning. 
* Summer 2023 - I taught a course (CS 220: Data Science Programming 1) during UW-Madison's summer session. 

-----
## Publications
(+) Equal contribution

**On Minimizing the Impact of Dataset Shifts on Actionable Explanations** <br/>
Anna P. Meyer (+), Dan Ley (+), Suraj Srinivas, and Himabindu Lakkaraju <br/>
*UAI 2023* <span style="color:red">(*Oral Presentation*)</span><br/>
[<a href="http://arxiv.org/abs/2306.06716">pdf</a>] [<a href="https://github.com/AI4LIFE-GROUP/robust-grads">code</a>]<br/>
**The Dataset Multiplicity Problem: How Unreliable Data Impacts Predictions** <br/>
Anna P. Meyer, Aws Albarghouthi, and Loris D'Antoni <br/>
*FAccT 2023*<br/>
[<a href="https://arxiv.org/abs/2304.10655">pdf</a>] [<a href="https://youtu.be/KxsdeJrvym0">video</a>] [<a href="https://github.com/annapmeyer/linear-bias-certification">code</a>] <br/> 
**Certifying Robustness to Programmable Data Bias in Decision Trees**  <br/>
Anna P. Meyer, Aws Albarghouthi, and Loris D'Antoni <br/>
*NeurIPS 2021*<br/>
[<a href="https://arxiv.org/abs/2110.04363">pdf</a>] [<a href="/files/dec_trees_slides.pdf">slides</a>] [<a href="https://youtu.be/kf5Geyr71T4">video</a>] [<a href="https://github.com/annapmeyer/antidote-P">code</a>] <br/>


-----
## Preprints and workshop papers
**Verified Training for Counterfactual Explanation Robustness under Data Shift** <br/>
Anna P. Meyer (+), Yuhao Zhang (+), Aws Albarghouthi, and Loris D'Antoni <br/>
*DMLR workshop at ICLR 2024*<br/>
[<a href="https://arxiv.org/abs/2403.03773">pdf</a>] [<a href="https://github.com/ForeverZyh/robust_cfx">code</a>] <br/>

