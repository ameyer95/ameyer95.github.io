---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

------
I research **multiplicity** in machine learning -- the fact that many models may perform equally well on a task according to standard accuracy metrics. Multiplicity can pose a problem for machine learning because individual decisions, if subject to change given multiplicity, become arbitrary. This arbitrariness may be unavoidable, but is often hidden, because alternative models and decisions are not considered.

I specifically focus on how **datasets** impact multiplicity: how different datasets may be equally well suited to a prediction task, yet yield models that behave differently in practice. My work uses techniques from *formal methods* and *machine learning* to computationally measure the impact that dataset multiplicity has on machine learning robustness. 

I'm currently in my fourth year in the Computer Sciences PhD program at UW-Madison. I'm part of the [MadPL](https://madpl.cs.wisc.edu/) group and am co-advised by [Aws Albarghouthi](http://pages.cs.wisc.edu/~aws/) and [Loris D'Antoni](https://pages.cs.wisc.edu/~loris/).

## News
* Summer 2023 - Taught a course (CS 220: Data Science Programming 1) during UW's summer session. 
* May 2023 - My paper, <a href="http://arxiv.org/abs/2306.06716">On Minimizing the Impact of Dataset Shifts on Actionable Explanations</a>, was accepted (with an oral presentation) at UAI
* April 2023 - This June, I will attend FAccT '23 in Chicago to present a paper (<a href="https://arxiv.org/abs/2304.10655">The Dataset Multiplicity Problem: How Unreliable Data Impacts Predictions</a>) and take part in the Doctoral Consortium 
* November 2022 - I was selected as a 2023 WISCIENCE [Public Service Fellow](https://wiscience.wisc.edu/service/public-service-fellows/) in the direct service pathway


-----
## Publications
**On Minimizing the Impact of Dataset Shifts on Actionable Explanations** <br/>
Anna P. Meyer (+), Dan Ley (+), Suraj Srinivas, and Himabindu Lakkaraju <br/>
*UAI 2023* <span style="color:red">(*Oral Presentation*)</span><br/>
[<a href="http://arxiv.org/abs/2306.06716">pdf</a>] [<a href="https://github.com/AI4LIFE-GROUP/robust-grads">code</a>]<br/>
**The Dataset Multiplicity Problem: How Unreliable Data Impacts Predictions** <br/>
Anna P. Meyer, Aws Albarghouthi, and Loris D'Antoni <br/>
*FAccT 2023*<br/>
[<a href="https://arxiv.org/abs/2304.10655">pdf</a>] [<a href="https://youtu.be/KxsdeJrvym0">video</a>] [<a href="https://github.com/annapmeyer/linear-bias-certification">code</a>] <br/> 
**Certifying Robustness to Programmable Data Bias in Decision Trees**  <br/>
Anna P. Meyer, Aws Albarghouthi, and Loris D'Antoni <br/>
*NeurIPS 2021*<br/>
[<a href="https://arxiv.org/abs/2110.04363">pdf</a>] [<a href="/files/dec_trees_slides.pdf">slides</a>] [<a href="https://youtu.be/kf5Geyr71T4">video</a>] [<a href="https://github.com/annapmeyer/antidote-P">code</a>] <br/>


(+) Equal contribution